{
  "linearLayers": [
    [
      [1, 0],
      [0, 1]
    ],
    [
      [1, 0],
      [0, 1]
    ],
    [
      [1, 1]
    ]
  ],
  "activationLayers": [
    "reLU",
    "reLU"
  ],
  "biases": [
    [1, 1],
    [1, 1],
    [1]
  ]
}